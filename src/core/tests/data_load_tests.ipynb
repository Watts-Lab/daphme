{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.fs as fs\n",
    "import pyarrow.dataset as ds\n",
    "import s3fs as fs3\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import daphmeIO\n",
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "import warnings\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test formats and folder structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import partitioned dataset (data 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_names = pd.read_csv('../../data/sample2/sample2.csv', nrows=0).columns\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = ds.dataset(path, format=\"parquet\", partitioning=\"hive\")\n",
    "df = dataset.to_table().to_pandas()\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions that check integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kind of based on scikit-mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _update_schema(original, new_labels):\n",
    "    updated_schema = dict(original)\n",
    "    for label in new_labels:\n",
    "        if label in constants.DEFAULT_SCHEMA:\n",
    "            updated_schema[label] = new_labels[label]\n",
    "    return updated_schema\n",
    "\n",
    "def _has_traj_cols(df, traj_cols):\n",
    "    \n",
    "    # Check for sufficient spatial columns\n",
    "    spatial_exists = (\n",
    "        ('latitude' in traj_cols and 'longitude' in traj_cols and \n",
    "         traj_cols['latitude'] in df and traj_cols['longitude'] in df) or\n",
    "        ('x' in traj_cols and 'y' in traj_cols and \n",
    "         traj_cols['x'] in df and traj_cols['y'] in df) or\n",
    "        ('geohash' in traj_cols and traj_cols['geohash'] in df)\n",
    "    )\n",
    "    \n",
    "    # Check for sufficient temporal columns\n",
    "    temporal_exists = (\n",
    "        ('datetime' in traj_cols and traj_cols['datetime'] in df) or\n",
    "        ('timestamp' in traj_cols and traj_cols['timestamp'] in df)\n",
    "    )\n",
    "    \n",
    "    if not spatial_exists:\n",
    "        raise ValueError(\n",
    "            \"Could not find required spatial columns in {}. The dataframe columns must contain or map to at least one of the following sets: \"\n",
    "            \"('latitude', 'longitude'), ('x', 'y'), or 'geohash'.\".format(df.columns.tolist())\n",
    "        )\n",
    "        \n",
    "    if not temporal_exists:\n",
    "        raise ValueError(\n",
    "            \"Could not find required temporal columns in {}. The dataframe columns must contain or map to either 'datetime' or 'timestamp'.\".format(df.columns.tolist())\n",
    "        )\n",
    "    \n",
    "    return spatial_exists and temporal_exists\n",
    "\n",
    "\n",
    "def _cast_traj_cols(df, traj_cols):\n",
    "    if 'datetime' in traj_cols and traj_cols['datetime'] in df:\n",
    "        if not pd.core.dtypes.common.is_datetime64_any_dtype(df[traj_cols['datetime']].dtype):\n",
    "            df[traj_cols['datetime']] = pd.to_datetime(df[traj_cols['datetime']])\n",
    "    if 'timestamp' in traj_cols and traj_cols['timestamp'] in df:\n",
    "        # Coerce to integer if it's not already\n",
    "        if not pd.core.dtypes.common.is_integer_dtype(df[traj_cols['timestamp']].dtype):\n",
    "            df[traj_cols['timestamp']] = df[traj_cols['timestamp']].astype(int)\n",
    "\n",
    "    float_cols = ['latitude', 'longitude', 'x', 'y']\n",
    "    for col in float_cols:\n",
    "        if col in traj_cols and traj_cols[col] in df:\n",
    "            if not pd.core.dtypes.common.is_float_dtype(df[traj_cols[col]].dtype):\n",
    "                df[traj_cols[col]] = df[traj_cols[col]].astype(\"float\")\n",
    "\n",
    "    string_cols = ['user_id', 'geohash']\n",
    "    for col in string_cols:\n",
    "        if col in traj_cols and traj_cols[col] in df:\n",
    "            if not pd.core.dtypes.common.is_string_dtype(df[traj_cols[col]].dtype):\n",
    "                df[traj_cols[col]] = df[traj_cols[col]].astype(\"str\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def _is_traj_df(df, traj_cols = None, **kwargs):\n",
    "    \n",
    "    if not (isinstance(df, pd.DataFrame) or isinstance(df, gpd.GeoDataFrame)):\n",
    "        return False\n",
    "    \n",
    "    if not traj_cols:\n",
    "        traj_cols = {}\n",
    "        traj_cols = _update_schema(traj_cols, kwargs) #kwargs ignored if traj_cols\n",
    "        \n",
    "    traj_cols = _update_schema(constants.DEFAULT_SCHEMA, traj_cols)\n",
    "    \n",
    "    if not _has_traj_cols(df, traj_cols):\n",
    "        return False\n",
    "    \n",
    "    if 'datetime' in traj_cols and traj_cols['datetime'] in df:\n",
    "        if not pd.core.dtypes.common.is_datetime64_any_dtype(df[traj_cols['datetime']].dtype):\n",
    "            return False\n",
    "    elif 'timestamp' in traj_cols and traj_cols['timestamp'] in df:\n",
    "        if not pd.core.dtypes.common.is_integer_dtype(df[traj_cols['timestamp']].dtype):\n",
    "            return False\n",
    "\n",
    "    float_cols = ['latitude', 'longitude', 'x', 'y']\n",
    "    for col in float_cols:\n",
    "        if col in traj_cols and traj_cols[col] in df:\n",
    "            if not pd.core.dtypes.common.is_float_dtype(df[traj_cols[col]].dtype):\n",
    "                return False\n",
    "\n",
    "    string_cols = ['user_id', 'geohash']\n",
    "    for col in string_cols:\n",
    "        if col in traj_cols and traj_cols[col] in df:\n",
    "            if not pd.core.dtypes.common.is_string_dtype(df[traj_cols[col]].dtype):\n",
    "                return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def from_object(df, traj_cols = None, spark_enabled=False, **kwargs):\n",
    "\n",
    "    if not (isinstance(df, pd.DataFrame) or isinstance(df, gpd.GeoDataFrame)):\n",
    "        raise TypeError(\n",
    "            \"Expected the data argument to be either a pandas DataFrame or a GeoPandas GeoDataFrame.\"\n",
    "        )\n",
    "    \n",
    "    # valid trajectory column names passed to **kwargs collected\n",
    "    if not traj_cols:\n",
    "        traj_cols = {}\n",
    "        traj_cols = _update_schema(traj_cols, kwargs) #kwargs ignored if traj_cols\n",
    "            \n",
    "    for key, value in traj_cols.items():\n",
    "        if value not in df:\n",
    "            warnings.warn(f\"Trajectory column '{value}' specified for '{key}' not found in df.\")\n",
    "            \n",
    "    # include defaults when missing\n",
    "    traj_cols = _update_schema(constants.DEFAULT_SCHEMA, traj_cols)\n",
    "    \n",
    "    if _has_traj_cols(df, traj_cols):\n",
    "        return _cast_traj_cols(df, traj_cols)\n",
    "    \n",
    "def from_file(filepath, format='csv', traj_cols = None, **kwargs):\n",
    "    assert format in ['parquet', 'csv']\n",
    "\n",
    "    if format=='parquet':\n",
    "        dataset = ds.dataset(filepath, format=\"parquet\", partitioning=\"hive\", **kwargs)\n",
    "        df = dataset.to_table().to_pandas()\n",
    "        return from_object(df, traj_cols = None, **kwargs)\n",
    "        \n",
    "    elif format=='csv':\n",
    "        if os.path.isdir(path):\n",
    "        \n",
    "    \n",
    "    if format == \"csv\":\n",
    "        print(\"lol\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../../data/sample1/r3234'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame([[1, 39.984094, 116.319236, '2008-10-23 13:53:05'],\n",
    " [1, 39.984198, 116.319322, '2008-10-23 13:53:06'],\n",
    " [1, 39.984224, 116.319402, '2008-10-23 13:53:11'],\n",
    " [1, 39.984211, 116.319389, '2008-10-23 13:53:16']], columns = ['uid', 'latitude', 'longitude', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "traj_cols = {'user_id':'uid',\n",
    "         'latitude':'latitude',\n",
    "         'longitude':'longitude',\n",
    "            'datetime':'time'}\n",
    "df = from_object(data, traj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_is_traj_df(df, traj_cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
