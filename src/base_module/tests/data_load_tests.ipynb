{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from .. import daphmeIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = daphmeIO.DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader.load_spark(\"s3://phl-pings/gravy/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = loader.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select('uid').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.selectExpr(\"grid as uid\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test formats and folder structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_parquet(\"s3://synthetic-raw-data/100-agents/sparse_trajectories.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow.fs as fs\n",
    "import pyarrow.dataset as ds\n",
    "import s3fs as fs3\n",
    "import pyarrow as pa\n",
    "import constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#using pyarrow.fs.S3FileSystem seems to break this\n",
    "s3 = fs3.S3FileSystem()\n",
    "\n",
    "path = \"s3://synthetic-raw-data/100-agents/sparse_trajectories.parquet\"\n",
    "dataset = ds.dataset(path[5:], format=\"parquet\", filesystem=s3)\n",
    "df = dataset.to_table().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['timestamp'], unit='s').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"../data/sample3/\"\n",
    "dataset = ds.dataset(path, format=\"parquet\", partitioning='hive')\n",
    "df = dataset.to_table().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import partitioned dataset (data 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_names = pd.read_csv('../../data/sample2/sample2.csv', nrows=0).columns\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#these can be passed as kwargs?\n",
    "traj_cols = {'user_id':'uid',\n",
    "             'latitude':'latitude',\n",
    "             'longitude':'longitude',\n",
    "             'time':'timestamp'}\n",
    "\n",
    "path = '../../data/sample3'\n",
    "single_user = False\n",
    "file_format = \"csv\"\n",
    "partitioning= \"hive\"\n",
    "filesystem = s3\n",
    "\n",
    "# we use pandas, pyarrow, or pyspark for reading a df, then we check if it has traj vars?\n",
    "# maybe we first test on a single row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "constants.DEFAULT_SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = ds.dataset(path, format=\"parquet\", partitioning=\"hive\")\n",
    "df = dataset.to_table().to_pandas()\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions that check integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kind of based on scikit-mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _update_schema(original, new_labels):\n",
    "    updated_schema = dict(original)\n",
    "    for label in new_labels:\n",
    "        if label in constants.SCHEMA_NAMES:\n",
    "            updated_schema[label] = new_labels[label]\n",
    "    return updated_schema\n",
    "\n",
    "def _has_traj_cols(df, traj_cols):\n",
    "    \n",
    "    # Check for sufficient spatial columns\n",
    "    spatial_exists = (\n",
    "        ('latitude' in traj_cols and 'longitude' in traj_cols and \n",
    "         traj_cols['latitude'] in df and traj_cols['longitude'] in df) or\n",
    "        ('x' in traj_cols and 'y' in traj_cols and \n",
    "         traj_cols['x'] in df and traj_cols['y'] in df) or\n",
    "        ('geohash' in traj_cols and traj_cols['geohash'] in df)\n",
    "    )\n",
    "    \n",
    "    # Check for sufficient temporal columns\n",
    "    temporal_exists = (\n",
    "        ('datetime' in traj_cols and traj_cols['datetime'] in df) or\n",
    "        ('timestamp' in traj_cols and traj_cols['timestamp'] in df)\n",
    "    )\n",
    "    \n",
    "    if not spatial_exists:\n",
    "        raise ValueError(\n",
    "            \"Missing required spatial columns. The dataframe must contain at least one of the following sets: \"\n",
    "            \"('latitude', 'longitude'), ('x', 'y'), or 'geohash'.\"\n",
    "        )\n",
    "        \n",
    "    if not temporal_exists:\n",
    "        raise ValueError(\n",
    "            \"Missing required temporal column. The dataframe must contain either 'datetime' or 'timestamp'.\"\n",
    "        )\n",
    "    \n",
    "    return spatial_exists and temporal_exists\n",
    "\n",
    "\n",
    "def _cast_traj_cols(df, traj_cols):\n",
    "    if 'datetime' in traj_cols and traj_cols['datetime'] in df:\n",
    "        if not pd.core.dtypes.common.is_datetime64_any_dtype(df[traj_cols['datetime']].dtype):\n",
    "            df[traj_cols['datetime']] = pd.to_datetime(df[traj_cols['datetime']])\n",
    "    if 'timestamp' in traj_cols and traj_cols['timestamp'] in df:\n",
    "        # Coerce to integer if it's not already\n",
    "        if not pd.core.dtypes.common.is_integer_dtype(df[traj_cols['timestamp']].dtype):\n",
    "            df[traj_cols['timestamp']] = df[traj_cols['timestamp']].astype(int)\n",
    "\n",
    "    float_cols = ['latitude', 'longitude', 'x', 'y']\n",
    "    for col in float_cols:\n",
    "        if col in traj_cols and traj_cols[col] in df:\n",
    "            if not pd.core.dtypes.common.is_float_dtype(df[traj_cols[col]].dtype):\n",
    "                df[traj_cols[col]] = df[traj_cols[col]].astype(\"float\")\n",
    "\n",
    "    string_cols = ['user_id', 'geohash']\n",
    "    for col in string_cols:\n",
    "        if col in traj_cols and traj_cols[col] in df:\n",
    "            if not pd.core.dtypes.common.is_string_dtype(df[traj_cols[col]].dtype):\n",
    "                df[traj_cols[col]] = df[traj_cols[col]].astype(\"str\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def _is_traj_df(df, traj_cols = None, **kwargs):\n",
    "    \n",
    "    if not (isinstance(df, pd.DataFrame) or isinstance(df, gpd.GeoDataFrame)):\n",
    "        return False\n",
    "    \n",
    "    if not traj_cols:\n",
    "        traj_cols = {}\n",
    "        traj_cols = _update_schema(traj_cols, kwargs) #kwargs ignored if traj_cols\n",
    "        \n",
    "    traj_cols = _update_schema(constants.DEFAULT_SCHEMA, traj_cols)\n",
    "    \n",
    "    if not _has_traj_cols(df, traj_cols):\n",
    "        return False\n",
    "    \n",
    "    if 'datetime' in traj_cols and traj_cols['datetime'] in df:\n",
    "        if not pd.core.dtypes.common.is_datetime64_any_dtype(df[traj_cols['datetime']].dtype):\n",
    "            return False\n",
    "    elif 'timestamp' in traj_cols and traj_cols['timestamp'] in df:\n",
    "        if not pd.core.dtypes.common.is_integer_dtype(df[traj_cols['timestamp']].dtype):\n",
    "            return False\n",
    "\n",
    "    float_cols = ['latitude', 'longitude', 'x', 'y']\n",
    "    for col in float_cols:\n",
    "        if col in traj_cols and traj_cols[col] in df:\n",
    "            if not pd.core.dtypes.common.is_float_dtype(df[traj_cols[col]].dtype):\n",
    "                return False\n",
    "\n",
    "    string_cols = ['user_id', 'geohash']\n",
    "    for col in string_cols:\n",
    "        if col in traj_cols and traj_cols[col] in df:\n",
    "            if not pd.core.dtypes.common.is_string_dtype(df[traj_cols[col]].dtype):\n",
    "                return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def from_object(df, traj_cols = None, spark_enabled=False, **kwargs):\n",
    "\n",
    "    if not (isinstance(df, pd.DataFrame) or isinstance(df, gpd.GeoDataFrame)):\n",
    "        raise TypeError(\n",
    "            \"Expected the data argument to be either a pandas DataFrame or a GeoPandas GeoDataFrame.\"\n",
    "        )\n",
    "    \n",
    "    # valid trajectory column names passed to **kwargs collected\n",
    "    if not traj_cols:\n",
    "        traj_cols = {}\n",
    "        traj_cols = _update_schema(traj_cols, kwargs) #kwargs ignored if traj_cols\n",
    "            \n",
    "    for key, value in traj_cols.items():\n",
    "        if value not in df:\n",
    "            warnings.warn(f\"Trajectory column '{value}' specified for '{key}' not found in df.\")\n",
    "            \n",
    "    # include defaults when missing\n",
    "    traj_cols = _update_schema(constants.DEFAULT_SCHEMA, traj_cols)\n",
    "    \n",
    "    if _has_traj_cols(df, traj_cols):\n",
    "        return _cast_traj_cols(df, traj_cols)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame([[1, 39.984094, 116.319236, '2008-10-23 13:53:05'],\n",
    " [1, 39.984198, 116.319322, '2008-10-23 13:53:06'],\n",
    " [1, 39.984224, 116.319402, '2008-10-23 13:53:11'],\n",
    " [1, 39.984211, 116.319389, '2008-10-23 13:53:16']], columns = ['uid', 'latitude', 'longitude', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "traj_cols = {'user_id':'uid',\n",
    "         'latitude':'latitude',\n",
    "         'longitude':'longitude',\n",
    "          'datetime':'time'}\n",
    "df = from_object(data, traj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_is_traj_df(df, traj_cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
